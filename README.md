# 模式识别实验一
实验人：
实验内容：
p.127  Prob. 1
(a)、编写程序，对实验数据中的W1的三个特征进行计算，求解最大似然估计u和δ；
(b)、处理二维数据，处理W1中的任意两个特征的组合；
(c)、处理三维数据，处理W1中的三个特征的组合；
(d)、在这三维高斯模型可分离的条件下，编写程序估计类别w2中的均值和协方差矩阵中的3个参数；
(e)、比较前4种方式计算出来的均值的异同，并加以解释；
(f)、比较前4种方式计算出来的方差的异同，并加以解释。

p.129  Prob. 9

(a)、编写用FISHER线性判别方法，对三维数据求最优方向w的通用程序；
(b)、对表格中的类别W2和W3，计算最优方向w;
(c)、画出表示最优方向w的直线，并且标记出投影后的点在直线上的位置；
(d)、在这个子空间中，对每种分布用一维高斯函数拟合，并且求分类决策面；
(e)、(b)中得到的分类器的训练误差是什么？
(f)、为了比较，使用非最优方向w=(1.0,2.0,-1.5)’重复(d)(e)两个步骤。在这个非最优子空间中，训练误差是什么。

# 模式识别实验二
实验人：
实验内容：
用课本中第五章算法3～12（除算法8外）在Iris数据集上进行分类。
(a)、对class1与class3采用算法3～12（除算法8外），从每类中随机选取25个样本用于训练分类器，其余25个样本用于测试分类器，重复该过程多遍，估计分类精度的均值及方差；
(b)、对class2与class3采用相应的算法，从每类中随机选取25个样本用于训练分类器，其余25个样本用于测试分类器，重复该过程多遍（100遍），估计分类精度的均值及方差；
Iris dataset available at www.ics.uci.edu/~mlearn/databases

# 模式识别实验三
实验人：
实验内容：
P409, Prob. 2
1、通过仿真，举例说明偏差-方差分解以及回归中的偏差-方差两难问题。假设目标函数F(x)=x^2，高斯噪声的方差是0.1。首先通过选择在-1<=x<=1上均匀分布的x的值，并将在F(x)上附加噪声，任意产生100个数据集，每个集的大小n=10。训练(a)~(d)中的每个回归函数的任意一个自由参数ai（用最小平方误差准则），每次只训练一组数据。作出式(11)中的直方图。对每个模型，利用你得到的结果去估计偏差和方差。
（a）g(x)=0.5
（b）g(x)=1.0
（c）g(x)=a0+a1*x
（d）g(x)=a0+a1*x+a2*x^2+a3*x^3
2、对100个数据集，其大小n=100重复问题(a)~(d)。

# 模式识别实验四
实验人：
实验内容：
P. 411, Prob. 7
1、研究“验证技术”未必会改善分类器的性能的情况。实验中分类器为“k-近邻分类器”，其中k是通过“验证技术”来设置。考虑一个二维的两类问题，其先验分布在范围0<=xi<=1（i=1，2）内是均匀分布。
（a）首先形成一个20个点的测试集Dtest——10个点属于w1，10个点属于w2——并根据“均匀分布”的方式任意选出。
（b）接下来产生100个点——每类50个模式。置gama=0.1，将该集合划分成一个训练集Dtrain（90个点）和一个验证集Dval（10个点）。
（c）产生一个“k-近邻分类器”，其中k一直增加到验证误差的第一个极小值被找到。（限定k为奇数值，以避免出现不分胜负的情况。）现利用测试集来确定该分类器的误差。
（d）重复（c），但通过验证误差的第一个极大值来确定k。
（e）重复（c）和（d）5次，注意所有10种情况下的测试误差。
（f）讨论结论——尤其是，它们是如何的依赖于（或不依赖于）其数据是“均匀分布”的事实的。

# 模式识别实验五
实验人：
实验内容：
P. 475-476, Probs. 2-3
1、写程序实现k-均值算法（算法1）和模糊k-均值聚类算法（算法2）并用表中的三维数据进行测试。其中距离采用Euclid距离d(x,y)=|| x-y||。
（a）c=2，m1（0）=（1,1,1）’，m2=（-1,1,-1）’。
（b）c=2，m1（0）=（0,0,0）’，m2=（1,1,-1）’。将得到的结果与（a）中的结果进行比较，并解释差别，包括迭代次数的差别。
（c）c=3，m1（0）=（0,0,0）’，m2（0）=（1,1,1）’，m3（0）=（-1,0,2）’
（d）c=3，m1（0）=（-0.1,0,0.1）’，m2（0）=（0,-0.1,0.1）’， m3（0）=（-0.1,-0.1,0.1）’。将得到的结果与（c）中的结果进行比较，并解释差别，包括迭代次数的差别。
2、重做1，其中距离改为d(x,y)^2=1-exp(-β*||x-y||^2)。其中β分别取0.001, 0.01, 0.1, 1, 10, 100. 

# 模式识别实验六
实验人：
实验内容：
(a)、用PCA方法对实验图像设计分类器并完成训练和分类过程，统计正确分类率,
其中求解特征值和特征向量的方法分为一般方法和使用技巧[1]的方法，比较二者的运行时间和正确分类率；
(b)、用MDA方法对实验图像设计分类器并完成训练和分类过程，统计正确分类率。
实验图像库为ORL人脸图像库，共40人，每人10幅图像，其中每人的前5幅作为训练样本，后5幅作为测试分类样本，统计正确分类率。分类准则为最近邻规则。
(c)、用距离保持的降维法(DPDR)[2]进行同样的实验并与PCA比较。
(d)、考察PCA和DPDR的外推能力， 即设TrSet和TeSET分别为训练和测试数据集， 现在 step1: 用TrSet获得投影阵M，用其重建TeSET，计算重建误差ETE,
        Step2: 用TrSet+TeSET获得投影阵M+,用其重建TeSET，计算重建误差ETE+,
        Step3: 比较ETE和ETE+，你能获得何种发现？ 
[1] see  “模式识别” 2nd Edition 2000年 
（清华出版社, Chapter 9, Section 9.9, pp. 223-228）
PCA：   
       ，其中 
Note： Scale reduction of XXT to XTX: DxD  nxn
For example, (112x92)x(112x92) 200x200 (the size of the training set)
ORL available at http://parnec.nuaa.edu.cn
[2] Hyunsoo Kim, Haesun Park, Hongyuan Zha, Distance Preserving Dimension Reduction Using the QR Factorization or the Cholesky Factorization, available by google (scholar)  
